{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Rugby Data (All Blacks & Ireland matches Oct 2003-Nov 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We'll be scraping data for All Black matches and Ireland matches starting from early October 2003 to present (Dec, 2018). We choose October 2003 as the starting point for all our data because World Rugby rankings weren't introduced before this. Data we'll be scraping will also include Opposition Name, Date of Match, Result of Match, Number of Debutants in the Opposition, Number of Debutants in the All Blacks/Ireland, Opposition Tries in Last 5 Games leading up the match, All Black/Ireland Tries in the Last 5 Games leading up to the match, Opposition Rating on the day of match, All Black/ Ireland Rating on the day of the match and Number of Games Since Last Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from numpy import arange\n",
    "\n",
    "page1 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;spanmax1=1st+Dec+201;spanmax2=1+Dec+2018;spanmin1=13+Oct+2003;spanmin2=13+Oct+2003;spanval1=span;spanval2=span;team=8;template=results;type=team;view=match\"\n",
    "page2 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=2;spanmax1=1st+Dec+201;spanmax2=1+Dec+2018;spanmin1=13+Oct+2003;spanmin2=13+Oct+2003;spanval1=span;spanval2=span;team=8;template=results;type=team;view=match\"\n",
    "page3 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=3;spanmax1=1st+Dec+201;spanmax2=1+Dec+2018;spanmin1=13+Oct+2003;spanmin2=13+Oct+2003;spanval1=span;spanval2=span;team=8;template=results;type=team;view=match\"\n",
    "page4 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=4;spanmax1=1st+Dec+201;spanmax2=1+Dec+2018;spanmin1=13+Oct+2003;spanmin2=13+Oct+2003;spanval1=span;spanval2=span;team=8;template=results;type=team;view=match\"\n",
    "page5 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=5;spanmax1=1st+Dec+201;spanmax2=1+Dec+2018;spanmin1=13+Oct+2003;spanmin2=13+Oct+2003;spanval1=span;spanval2=span;team=8;template=results;type=team;view=match\"\n",
    "\n",
    "startpos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Opposition Name','Date','Result','Location','Opposition Debutants','All Black Debutants','Opposition tries in last 5 games','All Black tries in last 5 games','Opposition Rating','All Black Rating','Games since last lost']\n",
    "ABMatchData = pd.DataFrame(columns=columns,index=range(0,204))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate First 4 Columns\n",
    "def populate_first4col(url, endoftable, startpos, dateendindx, resultendpos, TeamMatchData):\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "#extract HTML tags, only a portion of this list contains texts for opposition team name \n",
    "    AllItemsList = parser.find_all('td', class_=\"left\")\n",
    "    TextList = []\n",
    "    OppName = []\n",
    "    \n",
    "#extract list of HTML tags for dates and convert to Series\n",
    "    DatesList = []\n",
    "    AllDatesList = []\n",
    "    DatesList = parser.find_all('b')  \n",
    "    DatesList = DatesList[4:dateendindx]\n",
    "    for date in DatesList:\n",
    "        AllDatesList.append(date.text)\n",
    "    AllDatesSeries = pd.Series(AllDatesList)\n",
    "    \n",
    "#extract texts of opposition names from list of HTML tags\n",
    "    pos = 2\n",
    "    for item in AllItemsList:\n",
    "        TextList.append(item.text)\n",
    "\n",
    "    \n",
    "#extract only the texts of opposition team name and convert to series    \n",
    "    pos = 2\n",
    "    for x in range(0,len(AllItemsList)):\n",
    "        if pos == x:\n",
    "            OppName.append(TextList[pos])\n",
    "            pos = pos + 4\n",
    "\n",
    "    OppNameSeries = pd.Series(OppName)\n",
    "    \n",
    "#extract list of HTML tags for result and convert to Series\n",
    "    ResultList = []\n",
    "    TextResultList = []\n",
    "    ResultOnlyList = []\n",
    "    ResultList = parser.find_all('td') \n",
    "\n",
    "    for result in ResultList:\n",
    "        TextResultList.append(result.text)\n",
    "\n",
    "#len(TextResultList)\n",
    "    pos = 13\n",
    "    #resultendpos = 700\n",
    "    for x in range(0,len(TextResultList)):\n",
    "         if ((x==pos)and(x<resultendpos)):\n",
    "           # print(TextResultList[x])\n",
    "            ResultOnlyList.append(TextResultList[pos])\n",
    "            pos = pos + 14\n",
    "        \n",
    "    ResultSeries = pd.Series(ResultOnlyList)   \n",
    "    pos = 0\n",
    "\n",
    "#extract list of HTML tags for location and convert to Series\n",
    "    GroundList = []\n",
    "    TextGroundList = []\n",
    "    GroundOnlyList = []\n",
    "    GroundList = parser.find_all('a',class_='data-link') \n",
    "    for x in range(0,len(GroundList)):\n",
    "        if((x%2)!=0):\n",
    "            GroundOnlyList.append(GroundList[x].text)\n",
    "\n",
    "    LocationSeries=pd.Series(GroundOnlyList)\n",
    "    \n",
    "    \n",
    "#add Series of opposition names,dates,result and location to MatchData\n",
    "    for x in range(startpos,endoftable):\n",
    "        TeamMatchData.loc[x,'Opposition Name']=OppNameSeries[pos]\n",
    "        TeamMatchData.loc[x,'Date']=AllDatesSeries[pos]\n",
    "        TeamMatchData.loc[x,'Result']=ResultSeries[pos]\n",
    "        TeamMatchData.loc[x,'Location']=LocationSeries[pos]\n",
    "        pos = pos + 1\n",
    "        \n",
    "    pos = 0\n",
    "    #print(ResultSeries)\n",
    "        \n",
    "    startpos = endoftable\n",
    "    return startpos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate\n",
    "startpos = populate_first4col(page1,50,startpos,54,700,ABMatchData)\n",
    "startpos = populate_first4col(page2,100,startpos,54,700,ABMatchData)\n",
    "startpos = populate_first4col(page3,150,startpos,54,700,ABMatchData)\n",
    "startpos = populate_first4col(page4,200,startpos,54,700,ABMatchData)\n",
    "startpos = populate_first4col(page5,205,startpos,9,70,ABMatchData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our first 4 columns for our All Black DF should now be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### We need to clean the Opposition name column in order to use it to scrape for opposition tries in the last 5 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Opposition Name column to make URL to scrape tries in last 5 games\n",
    "for x in range(0,205):\n",
    "    name = str(ABMatchData.loc[x,'Opposition Name'])\n",
    "    cleanname=re.sub('v ','',name)\n",
    "    ABMatchData.loc[x,'Opposition Name']=cleanname\n",
    "\n",
    "#Get list of Unique Opponents\n",
    "OppList = ABMatchData['Opposition Name'].unique()\n",
    "\n",
    "#Make series with custom index for URL construction\n",
    "OppList.sort()\n",
    "OppList\n",
    "index=[10,6,25,1,14,9,81,3,20,23,32,82,121,27,12,15,2,5,16,11,4]\n",
    "OppSeries = pd.Series(OppList,index=index)\n",
    "\n",
    "#Tries in Last 5 games URL parts\n",
    "urlpart1 = 'http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;orderbyad=reverse;spanmax2='\n",
    "urlpart2 = ''#format is: 17+Oct+2003\n",
    "urlpart3 = ';spanmin2=1+Jan+2000;spanval2=span;team='\n",
    "urlpart4 = ''#ints from OppSeries index \n",
    "urlpart5 = ';template=results;type=team;view=match'\n",
    "accumtries = 0\n",
    "\n",
    "#Make complete URL to scrape try data from previous 5 games\n",
    "for x in range(0,205):\n",
    "    AllTagText = []\n",
    "    date=ABMatchData.loc[x,'Date']\n",
    "    urlpart2=str(re.sub(' ','+',date))\n",
    "    oppname=ABMatchData.loc[x,'Opposition Name']\n",
    "    urlpart4=str(OppSeries[OppSeries==oppname].index[0])\n",
    "    FullURL = urlpart1+urlpart2+urlpart3+urlpart4+urlpart5\n",
    "#start scraping again with new URL\n",
    "    time.sleep(10)\n",
    "    response = requests.get(FullURL)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    AllTriesTagList = parser.find_all('td')\n",
    "    for tag in AllTriesTagList:\n",
    "        AllTagText.append(tag.text)\n",
    "    trylocations=[28,42,56,70,84]\n",
    "    for loc in trylocations:\n",
    "        try:\n",
    "            accumtries = accumtries + int(AllTagText[loc])\n",
    "            ABMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "        except Exception:\n",
    "            ABMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "    ABMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "        \n",
    "    accumtries = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we do the exact same thing, just for the All Blacks instead of their opposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Insert tries in last 5 games for All Blacks\n",
    "\n",
    "#Tries in Last 5 games URL parts for All Blacks\n",
    "urlpart1 = 'http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;orderbyad=reverse;spanmax2='\n",
    "urlpart2 = ''#format is: 17+Oct+2003\n",
    "urlpart3 = ';spanmin2=1+Jan+2000;spanval2=span;team=8;template=results;type=team;view=match'\n",
    "accumtries = 0\n",
    "\n",
    "#Make complete URL to scrape try data from previous 5 games for ABs\n",
    "for x in ABMatchData.index:\n",
    "    AllTagText = []\n",
    "    date=ABMatchData.loc[x,'Date']\n",
    "    urlpart2=str(re.sub(' ','+',date))\n",
    "    FullURL = urlpart1+urlpart2+urlpart3\n",
    "#start scraping again with new URL\n",
    "    time.sleep(10)\n",
    "    response = requests.get(FullURL)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    AllTriesTagList = parser.find_all('td')\n",
    "    for tag in AllTriesTagList:\n",
    "        AllTagText.append(tag.text)\n",
    "    trylocations=[28,42,56,70,84]\n",
    "    for loc in trylocations:\n",
    "        try:\n",
    "            accumtries = accumtries + int(AllTagText[loc])\n",
    "            ABMatchData.loc[x,'All Black tries in last 5 games']=accumtries\n",
    "        except:\n",
    "            ABMatchData.loc[x,'All Black tries in last 5 games']=accumtries\n",
    "    accumtries = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our first 4 columns should now be filled along with Opposition and All Black tries in the last 5 games should be filled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we import debutant data and add it to our DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import debutant data\n",
    "ABDebutantData = pd.read_csv('ABDebutants.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add debutant data to MatchData DF\n",
    "ABMatchData['Opposition Debutants']=ABDebutantData['Opposition Debutants']\n",
    "ABMatchData['All Black Debutants']=ABDebutantData['All Black Debutants']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our debutant data should now be filled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ABMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pior to our first entry in the all blacks match record, their last loss was on the 14th of June 2003, let us account for this 8 game gap(keep in mind that this loss occured during a period where the world rankings had not yet been introduced, this is why our data does not start from this loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account for loss that occured before our first match date:\n",
    "lastloss = 8\n",
    "for x in range(0,5):\n",
    "    ABMatchData.loc[x,'Games since last loss']=lastloss\n",
    "    lastloss = lastloss+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currently our Result column is storing strings, lets convert them to ints in order to fill our Games since last loss column\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert str results to ints\n",
    "for x in ABMatchData.index:\n",
    "        ABMatchData.loc[x,'Result'] = int(ABMatchData.loc[x,'Result'])\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we fill in games since last loss based on the results column\n",
    "lastloss = 1\n",
    "for x in range(5,205):\n",
    "    if ABMatchData.loc[x-1,'Result'] >= 0:\n",
    "        ABMatchData.loc[x, 'Games since last loss'] = lastloss\n",
    "        lastloss = lastloss + 1\n",
    "    if ABMatchData.loc[x-1,'Result'] < 0:\n",
    "        lastloss = 1\n",
    "        ABMatchData.loc[x,'Games since last loss'] = lastloss\n",
    "        lastloss = lastloss + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets just do some house keeping and clear out the decimal points from our Games Since Last Loss column and then convert our date data from str to datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove decimal points in Games since last loss to ints        \n",
    "ABMatchData = ABMatchData.astype({'Games since last loss': int})\n",
    "\n",
    "#Convert date column from str to datetime\n",
    "ABMatchData['Date'] = pd.to_datetime(ABMatchData['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we import our rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABRankings = pd.read_csv('ABRankingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABMatchData['All Black Rating'] = ABRankings['All Black Rating']\n",
    "ABMatchData['Opposition Rating'] = ABRankings['Opposition Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our ABMatchData is now complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Now we do the exact same thing, just for <font color = green>Ireland</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;spanmax2=1+Dec+2018;spanmin2=13+Oct+2003;spanval2=span;team=3;template=results;type=team;view=match\"\n",
    "page2 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=2;spanmax2=1+Dec+2018;spanmin2=13+Oct+2003;spanval2=span;team=3;template=results;type=team;view=match\"\n",
    "page3 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=3;spanmax2=1+Dec+2018;spanmin2=13+Oct+2003;spanval2=span;team=3;template=results;type=team;view=match\"\n",
    "page4 = \"http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;page=4;spanmax2=1+Dec+2018;spanmin2=13+Oct+2003;spanval2=span;team=3;template=results;type=team;view=match\"\n",
    "startpos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Opposition Name','Date','Result','Location','Opposition Debutants','Ireland Debutants','Opposition tries in last 5 games','Ireland tries in last 5 games','Opposition Rating','Ireland Rating','Games since last loss']\n",
    "IREMatchData = pd.DataFrame(columns=columns,index=range(0,171))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "startpos = populate_first4col(page1,50,startpos,54,700,IREMatchData)\n",
    "startpos = populate_first4col(page2,100,startpos,54,700,IREMatchData)\n",
    "startpos = populate_first4col(page3,150,startpos,54,700,IREMatchData)\n",
    "startpos = populate_first4col(page4,172,startpos,26,308,IREMatchData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our first 4 columns for IREMatchData should now be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IREMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we insert tries in last 5 games, we start by cleaning our opposition name column and preparing our URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Opposition Name column to make URL to scrape tries in last 5 games for opposition\n",
    "for x in IREMatchData.index:\n",
    "    name = str(IREMatchData.loc[x,'Opposition Name'])\n",
    "    cleanname=re.sub('v ','',name)\n",
    "    IREMatchData.loc[x,'Opposition Name']=cleanname\n",
    "\n",
    "#Get list of Unique Opponents\n",
    "OppList = IREMatchData['Opposition Name'].unique()\n",
    "\n",
    "#Make series with custom index for URL construction\n",
    "OppList.sort()\n",
    "OppList\n",
    "index=[10,6,25,1,14,9,81,20,23,82,8,121,12,57,15,2,5,11,4]\n",
    "OppSeries = pd.Series(OppList,index=index)\n",
    "\n",
    "#Tries in Last 5 games URL parts\n",
    "urlpart1 = 'http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;orderbyad=reverse;spanmax2='\n",
    "urlpart2 = ''#format is: 17+Oct+2003\n",
    "urlpart3 = ';spanmin2=1+Jan+2000;spanval2=span;team='\n",
    "urlpart4 = ''#ints from OppSeries index \n",
    "urlpart5 = ';template=results;type=team;view=match'\n",
    "accumtries = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make complete URL to scrape try data from previous 5 games for opposition\n",
    "for x in IREMatchData.index:\n",
    "    AllTagText = []\n",
    "    date=IREMatchData.loc[x,'Date']\n",
    "    urlpart2=str(re.sub(' ','+',date))\n",
    "    oppname=IREMatchData.loc[x,'Opposition Name']\n",
    "    urlpart4=str(OppSeries[OppSeries==oppname].index[0])\n",
    "    FullURL = urlpart1+urlpart2+urlpart3+urlpart4+urlpart5\n",
    "#start scraping again with new URL\n",
    "    time.sleep(10)\n",
    "    response = requests.get(FullURL)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    AllTriesTagList = parser.find_all('td')\n",
    "    for tag in AllTriesTagList:\n",
    "        AllTagText.append(tag.text)\n",
    "    trylocations=[28,42,56,70,84]\n",
    "    for loc in trylocations:\n",
    "        try:\n",
    "            accumtries = accumtries + int(AllTagText[loc])\n",
    "            IREMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "        except Exception:\n",
    "            IREMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "    IREMatchData.loc[x,'Opposition tries in last 5 games']=accumtries\n",
    "        \n",
    "    accumtries = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opposition tries in last 5 games should now be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "IREMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we fill in Tries in the Last 5 games for Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-0a2b1ab4ba43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mAllTagText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIREMatchData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0murlpart2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mFullURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlpart1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murlpart2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murlpart3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#start scraping again with new URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#Insert tries in last 5 games for Ireland\n",
    "\n",
    "#Tries in Last 5 games URL parts for Ireland\n",
    "urlpart1 = 'http://stats.espnscrum.com/statsguru/rugby/stats/index.html?class=1;orderby=date;orderbyad=reverse;spanmax2='\n",
    "urlpart2 = ''#format is: 17+Oct+2003\n",
    "urlpart3 = ';spanmin2=1+Jan+2000;spanval2=span;team=3;template=results;type=team;view=match'\n",
    "accumtries = 0\n",
    "\n",
    "#Make complete URL to scrape try data from previous 5 games for Ireland\n",
    "#for x in IREMatchData.index:\n",
    "for x in range(0,172):\n",
    "    AllTagText = []\n",
    "    date=IREMatchData.loc[x,'Date']\n",
    "    urlpart2=str(re.sub(' ','+',date))\n",
    "    FullURL = urlpart1+urlpart2+urlpart3\n",
    "#start scraping again with new URL\n",
    "    time.sleep(10)\n",
    "    response = requests.get(FullURL)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    AllTriesTagList = parser.find_all('td')\n",
    "    for tag in AllTriesTagList:\n",
    "        AllTagText.append(tag.text)\n",
    "    trylocations=[28,42,56,70,84]\n",
    "    for loc in trylocations:\n",
    "        try:\n",
    "            accumtries = accumtries + int(AllTagText[loc])\n",
    "            IREMatchData.loc[x,'Ireland tries in last 5 games']=accumtries\n",
    "        except:\n",
    "            IREMatchData.loc[x,'Ireland tries in last 5 games']=accumtries\n",
    "    accumtries = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Ireland Tries in the Last 5 games should also be filled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "IREMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similiar to the All Blacks, the Irish also suffered a loss before the first match in our data. Let us account for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account for loss that occured before our first match date:\n",
    "lastloss = 7\n",
    "for x in range(0,3):\n",
    "    IREMatchData.loc[x,'Games since last loss']=lastloss\n",
    "    lastloss = lastloss+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert str results to ints\n",
    "for x in IREMatchData.index:\n",
    "        IREMatchData.loc[x,'Result'] = int(IREMatchData.loc[x,'Result'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in rest of last loss data\n",
    "lastloss = 1\n",
    "for x in range(3,172):\n",
    "    if IREMatchData.loc[x-1,'Result'] >= 0:\n",
    "        IREMatchData.loc[x, 'Games since last loss'] = lastloss\n",
    "        lastloss = lastloss + 1\n",
    "    if IREMatchData.loc[x-1,'Result'] < 0:\n",
    "        lastloss = 1\n",
    "        IREMatchData.loc[x,'Games since last loss'] = lastloss\n",
    "        lastloss = lastloss + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets do some quick house keeping before going any further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove decimal points         \n",
    "IREMatchData = IREMatchData.astype({'Games since last loss': int})\n",
    "IREMatchData = IREMatchData.astype({'Ireland tries in last 5 games': int})\n",
    "\n",
    "\n",
    "#Convert date column from str to datetime\n",
    "IREMatchData['Date'] = pd.to_datetime(IREMatchData['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we import our Debutant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import debutant data and assign to columns\n",
    "IREDebutantData = pd.read_csv('IREDebutants.csv')\n",
    "IREMatchData['Opposition Debutants'] = IREDebutantData['Opposition Debutants']\n",
    "IREMatchData['Ireland Debutants'] = IREDebutantData['Ireland Debutants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "IREMatchData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we import our rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRERankingData = pd.read_csv('IRERankingData.csv')\n",
    "IREMatchData['Opposition Rating'] = IRERankingData['Opposition Rating']\n",
    "IREMatchData['Ireland Rating'] = IRERankingData['Ireland Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now our <font color = green>Irish</font> DF is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
